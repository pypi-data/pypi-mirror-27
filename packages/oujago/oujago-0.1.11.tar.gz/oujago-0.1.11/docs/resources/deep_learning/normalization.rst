
===================
Batch Normalization
===================

Papers
------
* [15.02]  `Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift <http://arxiv.org/abs/1502.03167>`_
* [15.10]  `Batch Normalized Recurrent Neural Networks <http://arxiv.org/abs/1510.01378>`_
* [16.03]  `Recurrent Batch Normalization <http://arxiv.org/abs/1603.09025>`_
* [16.07]  `Layer Normalization <https://arxiv.org/abs/1607.06450>`_


Codes
-----

* `Batch Normalized Recurrent Neural Networks <https://github.com/GabrielPereyra/norm-rnn>`_, theano implementation
* `Recurrent Batch Normalization <https://github.com/cooijmanstim/recurrent-batch-normalization>`_, theano(blocks) implementation
* `Layer Normalization <https://github.com/pbhatia243/tf-layer-norm>`_, tensorflow implementation
* `Layer Normalization <https://github.com/ryankiros/layer-norm>`_, theano implementation


Blogs
-----

* `Why does batch normalization help? <https://www.quora.com/Why-does-batch-normalization-help>`_, Quora
* `深度学习（二十九）Batch Normalization 学习笔记 <http://blog.csdn.net/hjimce/article/details/50866313>`_ , hjimce的专栏
* `解读Batch Normalization <http://blog.csdn.net/elaine_bao/article/details/50890491>`_, elaine_bao的专栏
* `BatchNormalization 代码实现  <http://blog.csdn.net/elaine_bao/article/details/50923198>`_, elaine_bao的专栏
* `《Batch Normalization》阅读笔记与实现 <http://blog.csdn.net/happynear/article/details/44238541>`_, happynear的专栏
* `深度学习中 Batch Normalization为什么效果好？ <https://www.zhihu.com/question/38102762>`_, 知乎




