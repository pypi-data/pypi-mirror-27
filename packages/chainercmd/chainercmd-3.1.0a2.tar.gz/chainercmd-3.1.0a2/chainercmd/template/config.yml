stop_trigger: [20, "epoch"]
# max_workspace_size: 8388608  # default: 8 * 1024 * 1024

dataset:
    train:
        file: dataset.py
        name: MNIST
        batchsize: 128
        args:
            split: train
            ndim: 3
    valid:
        file: dataset.py
        name: MNIST
        batchsize: 64
        args:
            split: valid
            ndim: 3

model:
    file: model.py
    name: LeNet5
    args:
        n_class: 10

loss:
    file: loss.py
    name: Classifier

optimizer:
    method: MomentumSGD
    args:
        lr: 0.01
    weight_decay: 0.0001
    lr_drop_ratio: 0.1
    lr_drop_triggers:
        points: [10, 15]
        unit: epoch

updater_creator:
    file: updater_creator.py
    name: updater_creator

trainer_extension:
    - custom:
        file: custom_extension.py
        name: CustomExtension
        args:
            message: 'I am learning...'
        trigger: [20, "epoch"]
    - LogReport:
        trigger: [1, "epoch"]
    - dump_graph:
        root_name: "main/loss"
        out_name: "cg.dot"
    - observe_lr:
        trigger: [1, "epoch"]
    - Evaluator:
        file: evaluator_creator.py
        name: evaluator_creator
        trigger: [1, "epoch"]
        prefix: val
    - PlotReport:
        y_keys:
            - "main/loss"
            - "val/main/loss"
        x_key: epoch
        file_name: loss.png
        trigger: [1, "epoch"]
    - PlotReport:
        y_keys:
            - "main/accuracy"
            - "val/main/accuracy"
        x_key: epoch
        file_name: accuracy.png
        trigger: [1, "epoch"]
    - PrintReport:
        entries:
            - "epoch"
            - "iteration"
            - "main/loss"
            - "main/accuracy"
            - "val/main/loss"
            - "val/main/accuracy"
            - "elapsed_time"
            - "lr"
        trigger: [1, "epoch"]
    - ProgressBar:
        update_interval: 10
        trigger: [10, "iteration"]
    - snapshot:
        filename: trainer_{.updater.epoch}_epoch
        trigger: [10, "epoch"]
