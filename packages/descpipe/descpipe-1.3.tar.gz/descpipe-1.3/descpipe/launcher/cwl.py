import os
import sys
from .. import utils
from .launcher import Launcher
from ..errors import InputError
import shutil

class CWLLauncher(Launcher):

    def workflow_inputs(self):
        inputs = {}
        for tag in self.pipeline.input_tags():
            inputs[tag] = "File"
        return inputs

    def _generate_stage_tool(self, dirname, stage_name, stage_class):
        import yaml
        tool = {}
        tool['class'] = "CommandLineTool"
        tool['cwlVersion'] = 'v1.0'
        tool['stderr'] = '{}-stderr.txt'.format(stage_name)
        tool['stdout'] = '{}-stdout.txt'.format(stage_name)

        image = self.pipeline.image_name(stage_name)
        tool['requirements'] = {'DockerRequirement':{'dockerPull':image}}

        position = 1
        inputs = {}
        for tag,file_type in stage_class.inputs.items():
            binding = {'prefix':'input:{}.{}='.format(tag,file_type), 'separate':False, 'position':position}
            inputs[tag] = {'type':'File', 'inputBinding':binding}
            position += 1

        for tag,filename in stage_class.config.items():
            qualified_tag = "{}.{}".format(stage_name,tag)
            binding = {'prefix':'config:{}='.format(filename), 'separate':False, 'position':position}
            inputs[tag] = {'type':'File', 'inputBinding':binding}
            position += 1


        tool['inputs'] = inputs
        
        outputs = {}
        arguments = []
        for tag,file_type in stage_class.outputs.items():
            output_filename = '{}.{}'.format(tag, file_type)
            outputs[tag] = {'type':'File', 'outputBinding':{'glob':output_filename}}
            arguments.append("output:{}={}".format(tag,output_filename))
        tool['outputs'] = outputs
        tool['arguments'] = arguments

        tool['baseCommand'] = '/opt/desc/cwl-run.sh'.split()

        filename = self._tool_filename(dirname, stage_name)
        tool_file = open(filename, 'w')
        tool_file.write("#!/usr/bin/env cwl-runner\n")
        yaml.dump(tool, tool_file)
        tool_file.close()

            

    def _tool_filename(self, dirname, stage_name):
        filename = os.path.join(dirname, stage_name+'.tool')
        return filename


    def generate(self, dirname):
        "Generate the CWL files for the pipeline in the given directory."
        import yaml

        # The goal of this method is to build up the dictionaries
        # that get dumped in YAML format as CWL files.  We are generating
        # two overall files (one for the workflow as a whole and one for 
        # this specific job) and one per stage of the pipeline.

        # This is the structure for the overall workflow file.
        workflow = {}
        workflow['class'] = "Workflow"
        workflow['cwlVersion'] = 'v1.0'

        # The overall components include various dictionaries
        # that we build up by going through the stages
        steps = {}
        overall_inputs = {}
        overall_outputs = {}

        # We will build these up.
        workflow['outputs'] = overall_outputs
        workflow['steps'] = steps

        # Record where inputs come from for later stages
        # this information should be in the pipeline object I think
        input_sources = {}

        # Configuration files. These have a slightly different
        # behaviour than input files because they can never be
        # generated by a previous stage and can have the same name
        # between different steps in the pipeline
        # config_files = {}
        
        # Overall inputs for the whole pipeline, which must
        # be specified in the input process.
        for tag in self.pipeline.input_tags():
            overall_inputs[tag] = {'type':'File'}

        # This is for the second output file.  It is for overall
        # inputs to the whole pipeline.  We will add soem more things 
        job = {}
        for tag in overall_inputs:
            path = self.info['inputs'].get(tag)
            path = os.path.abspath(path)
            job[tag] = {'class':'File', 'path':path}


        # We need a copy of the overall inputs dictionary, because
        # we will be adding some configuration files as well which 
        # won't be used as inputs passed from one stage to the next,
        # which is what the overall_inputs dict is for
        workflow['inputs'] = overall_inputs.copy()


        # All the stages in the pipeline
        for stage_name, stage_class in self.pipeline.sequence():
            # Each stage needs a separate CWL file as well as this main one.
            # We make that in here.
            self._generate_stage_tool(dirname, stage_name, stage_class)

            # Each stage ('step' in the CWL lingo)
            # is its own 
            stage = {}
            steps[stage_name] = stage
            stage['run'] = stage_name + '.tool'

            # Outputs.  We do two things:
            # Record for the overall pipeline that this is an output
            # Record that it is an output for this particular stage,
            # So that later stages can find it.
            output_tags = list(stage_class.outputs.keys())
            stage['out'] = output_tags
            for tag in output_tags:
                overall_outputs[tag] = {'type':'File', 'outputSource':"{}/{}".format(stage_name,tag)}
                input_sources[tag] = stage_name

            # Inputs to this stage.
            # There are two cases - either an input can come from outside the pipeline,
            # or from an earlier stage within it.
            # CWL uses the format_name/tag to show the latter
            # We record this in the stage specification.
            inputs = {}
            stage['in'] = inputs
            for tag in stage_class.inputs:
                if tag in input_sources:
                    inputs[tag] = '{}/{}'.format(input_sources[tag], tag)
                else:
                    inputs[tag] = tag

            # Config files.  These must always be specified from outside the job,
            # never from a previous stage.
            for tag in stage_class.config:
                # Because config tags can be non-unique between stages
                # we have to qualify the tag
                qualified_tag = "{}.{}".format(stage_name,tag)
                # Find the overall absolute pipeline input path
                path = self.info['config'][stage_name][tag]
                path = os.path.abspath(path)

                # We record this information in three places.
                # 1. The list of inputs for this stage
                # 2. The list of inputs to the whole pipeline
                # 3. The list of inputs to the whole job.
                # config_files[qualified_tag] = path
                inputs[tag] = qualified_tag
                job[qualified_tag] = {'class':'File', 'path':path}
                workflow['inputs'][qualified_tag] = {'type': 'File'}


        # We now dump the two objects we have built up into YAML files.
        # First the workflow
        utils.mkdir_p(dirname)
        filename = os.path.join(dirname, 'workflow.cwl')
        workflow_file = open(filename, 'w')
        workflow_file.write("#!/usr/bin/env cwl-runner\n")
        yaml.dump(workflow, workflow_file)

        # And then the job
        filename = os.path.join(dirname, 'job.yml')
        job_file = open(filename, 'w')
        yaml.dump(job, job_file)


        user_flag = "--no-match-user" if sys.platform == "darwin" else ""
        tmpdir = "{}/runtime".format(dirname)
        outdir = self.output_dir()
        utils.mkdir_p(tmpdir)
        cmd = "TMPDIR={tmpdir} cwltool {user_flag} --no-read-only --outdir={outdir} {dirname}/workflow.cwl {dirname}/job.yml".format(
            tmpdir=tmpdir, user_flag=user_flag, dirname=dirname, outdir=outdir)
        print("Run this command to execute pipeline locally:")
        print(cmd)





